# LLM Endpoint Configuration
# Uses local model server by default - OPENAI_API_KEY is not required for local endpoints
OPENAI_BASE_URL=http://192.168.1.79:8080/v1/
OPENAI_MODEL=openai/gpt-oss-120b
# OPENAI_API_KEY=dummy-key-for-local-endpoint  # Only needed for non-local endpoints

# Langfuse Tracing (optional)
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=http://localhost:3000