{
  "version": "1",
  "metadata": {
    "marimo_version": "0.19.4"
  },
  "cells": [
    {
      "id": "Hbol",
      "code_hash": "08017a9d4a5b04e9488da5f3cc16ae35",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h1 id=\"the-agent-loop-building-production-agents-with-langchain-10\">The Agent Loop: Building Production Agents with LangChain 1.0</h1>\n<span class=\"paragraph\">In this notebook, we'll explore the foundational concepts of AI agents and learn how to build production-grade agents using LangChain's new <code>create_agent</code> abstraction with middleware support.</span>\n<span class=\"paragraph\"><strong>Learning Objectives:</strong></span>\n<ul>\n<li>Understand what an \"agent\" is and how the agent loop works</li>\n<li>Learn the core constructs of LangChain (Runnables, LCEL)</li>\n<li>Master the <code>create_agent</code> function and middleware system</li>\n<li>Build an agentic RAG application using Qdrant</li>\n</ul>\n<h2 id=\"table-of-contents\">Table of Contents:</h2>\n<ul>\n<li>\n<span class=\"paragraph\"><strong>Breakout Room #1:</strong> Introduction to LangChain, LangSmith, and <code>create_agent</code></span>\n<ul>\n<li>Task 1: Dependencies</li>\n<li>Task 2: Environment Variables</li>\n<li>Task 3: LangChain Core Concepts (Runnables &amp; LCEL)</li>\n<li>Task 4: Understanding the Agent Loop</li>\n<li>Task 5: Building Your First Agent with <code>create_agent()</code></li>\n<li>Question #1 &amp; Question #2</li>\n<li>Activity #1: Create a Custom Tool</li>\n</ul>\n</li>\n<li>\n<span class=\"paragraph\"><strong>Breakout Room #2:</strong> Middleware - Agentic RAG with Qdrant</span>\n<ul>\n<li>Task 6: Loading &amp; Chunking Documents</li>\n<li>Task 7: Setting up Qdrant Vector Database</li>\n<li>Task 8: Creating a RAG Tool</li>\n<li>Task 9: Introduction to Middleware</li>\n<li>Task 10: Building Agentic RAG with Middleware</li>\n<li>Question #3 &amp; Question #4</li>\n<li>Activity #2: Enhance the Agent</li>\n</ul>\n</li>\n</ul></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "MJUe",
      "code_hash": "c69793fe62bad46c7092b7de29ed944b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><hr />\n<h1 id=\"breakout-room-1\">\ud83e\udd1d Breakout Room #1</h1>\n<h2 id=\"introduction-to-langchain-langsmith-and-create_agent\">Introduction to LangChain, LangSmith, and <code>create_agent</code></h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vblA",
      "code_hash": "a3bb194dce0b08a40340cf625cfcfe2b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-1-dependencies\">Task 1: Dependencies</h2>\n<span class=\"paragraph\">First, let's ensure we have all the required packages installed. We'll be using:</span>\n<ul>\n<li><strong>LangChain 1.0+</strong>: The core framework with the new <code>create_agent</code> API</li>\n<li><strong>LangChain-OpenAI</strong>: OpenAI model integrations</li>\n<li><strong>LangSmith</strong>: Observability and tracing</li>\n<li><strong>Qdrant</strong>: Vector database for RAG</li>\n<li><strong>tiktoken</strong>: Token counting for text splitting</li>\n</ul></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "PKri",
      "code_hash": "7b103aabd1a3571fa0a96cfc1a2ab489",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-2-environment-variables\">Task 2: Environment Variables</h2>\n<span class=\"paragraph\">We need to set up our API keys for:</span>\n<ol>\n<li><strong>OpenAI</strong> - For the GPT-5 model</li>\n<li><strong>LangSmith</strong> - For tracing and observability (optional but recommended)</li>\n</ol></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "BYtC",
      "code_hash": "c149fe0ef7e51b6d0d9c4182abf0e5e9",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-3-langchain-core-concepts\">Task 3: LangChain Core Concepts</h2>\n<span class=\"paragraph\">Before diving into agents, let's understand the fundamental building blocks of LangChain.</span>\n<h3 id=\"what-is-a-runnable\">What is a Runnable?</h3>\n<span class=\"paragraph\">A <strong>Runnable</strong> is the core abstraction in LangChain - think of it as a standardized component that:</span>\n<ul>\n<li>Takes an input</li>\n<li>Performs some operation</li>\n<li>Returns an output</li>\n</ul>\n<span class=\"paragraph\">Every component in LangChain (models, prompts, retrievers, parsers) is a Runnable, which means they all share the same interface:</span>\n<div class=\"language-python codehilite\"><pre><span></span><code><span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">runnable</span><span class=\"o\">.</span><span class=\"n\">invoke</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>           <span class=\"c1\"># Single input</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">runnable</span><span class=\"o\">.</span><span class=\"n\">batch</span><span class=\"p\">([</span><span class=\"n\">input1</span><span class=\"p\">,</span> <span class=\"n\">input2</span><span class=\"p\">])</span> <span class=\"c1\"># Multiple inputs</span>\n<span class=\"k\">for</span> <span class=\"n\">chunk</span> <span class=\"ow\">in</span> <span class=\"n\">runnable</span><span class=\"o\">.</span><span class=\"n\">stream</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">):</span>       <span class=\"c1\"># Streaming</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">chunk</span><span class=\"p\">)</span>\n</code></pre></div>\n<h3 id=\"what-is-lcel-langchain-expression-language\">What is LCEL (LangChain Expression Language)?</h3>\n<span class=\"paragraph\"><strong>LCEL</strong> allows you to chain Runnables together using the <code>|</code> (pipe) operator:</span>\n<div class=\"language-python codehilite\"><pre><span></span><code><span class=\"n\">chain</span> <span class=\"o\">=</span> <span class=\"n\">prompt</span> <span class=\"o\">|</span> <span class=\"n\">model</span> <span class=\"o\">|</span> <span class=\"n\">output_parser</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">chain</span><span class=\"o\">.</span><span class=\"n\">invoke</span><span class=\"p\">({</span><span class=\"s2\">&quot;query&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;Hello!&quot;</span><span class=\"p\">})</span>\n</code></pre></div>\n<span class=\"paragraph\">This is similar to Unix pipes - the output of one component becomes the input to the next.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "emfo",
      "code_hash": "bf95a8073b026eb8022f13ae15b85f36",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-4-understanding-the-agent-loop\">Task 4: Understanding the Agent Loop</h2>\n<h3 id=\"what-is-an-agent\">What is an Agent?</h3>\n<span class=\"paragraph\">An <strong>agent</strong> is a system that uses an LLM to decide what actions to take. Unlike a simple chain that follows a fixed sequence, an agent can:</span>\n<ol>\n<li><strong>Reason</strong> about what to do next</li>\n<li><strong>Take actions</strong> by calling tools</li>\n<li><strong>Observe</strong> the results</li>\n<li><strong>Iterate</strong> until the task is complete</li>\n</ol>\n<h3 id=\"the-agent-loop\">The Agent Loop</h3>\n<span class=\"paragraph\">The core of every agent is the <strong>agent loop</strong>:</span>\n<div class=\"language-ecl codehilite\"><pre><span></span><code><span class=\"w\">                          </span><span class=\"n\">AGENT</span><span class=\"w\"> </span><span class=\"nf\">LOOP</span>\n\n<span class=\"w\">      </span><span class=\"o\">+----------+</span><span class=\"w\">     </span><span class=\"o\">+----------+</span><span class=\"w\">     </span><span class=\"o\">+----------+</span>\n<span class=\"w\">      </span><span class=\"o\">|</span><span class=\"w\">  </span><span class=\"n\">Model</span><span class=\"w\">   </span><span class=\"o\">|</span><span class=\"w\"> </span><span class=\"o\">--&gt;</span><span class=\"w\"> </span><span class=\"o\">|</span><span class=\"w\">   </span><span class=\"n\">Tool</span><span class=\"w\">   </span><span class=\"o\">|</span><span class=\"w\"> </span><span class=\"o\">--&gt;</span><span class=\"w\"> </span><span class=\"o\">|</span><span class=\"w\">  </span><span class=\"n\">Model</span><span class=\"w\">   </span><span class=\"o\">|</span><span class=\"w\"> </span><span class=\"o\">--&gt;</span><span class=\"w\"> </span><span class=\"p\">...</span>\n<span class=\"w\">      </span><span class=\"o\">|</span><span class=\"w\">   </span><span class=\"n\">Call</span><span class=\"w\">   </span><span class=\"o\">|</span><span class=\"w\">     </span><span class=\"o\">|</span><span class=\"w\">   </span><span class=\"n\">Call</span><span class=\"w\">   </span><span class=\"o\">|</span><span class=\"w\">     </span><span class=\"o\">|</span><span class=\"w\">   </span><span class=\"n\">Call</span><span class=\"w\">   </span><span class=\"o\">|</span>\n<span class=\"w\">      </span><span class=\"o\">+----------+</span><span class=\"w\">     </span><span class=\"o\">+----------+</span><span class=\"w\">     </span><span class=\"o\">+----------+</span>\n<span class=\"w\">           </span><span class=\"o\">|</span><span class=\"w\">                                  </span><span class=\"o\">|</span>\n<span class=\"w\">           </span><span class=\"n\">v</span><span class=\"w\">                                  </span><span class=\"n\">v</span>\n<span class=\"w\">      </span><span class=\"s\">&quot;Use search&quot;</span><span class=\"w\">                   </span><span class=\"s\">&quot;Here&#39;</span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">answer</span><span class=\"s\">&quot;</span>\n</code></pre></div>\n<ol>\n<li>\n<span class=\"paragraph\"><strong>Model Call</strong>: The LLM receives the current state and decides whether to:</span>\n<ul>\n<li>Call a tool (continue the loop)</li>\n<li>Return a final answer (exit the loop)</li>\n</ul>\n</li>\n<li><strong>Tool Call</strong>: If the model decides to use a tool, the tool is executed and its output is added to the conversation</li>\n<li><strong>Repeat</strong>: The loop continues until the model decides it has enough information to answer</li>\n</ol>\n<h3 id=\"why-create_agent\">Why <code>create_agent</code>?</h3>\n<span class=\"paragraph\">LangChain 1.0 introduced <code>create_agent</code> as the new standard way to build agents. It provides:</span>\n<ul>\n<li><strong>Simplified API</strong>: One function to create production-ready agents</li>\n<li><strong>Middleware Support</strong>: Hook into any point in the agent loop</li>\n<li><strong>Built on LangGraph</strong>: Uses the battle-tested LangGraph runtime under the hood</li>\n</ul></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Hstk",
      "code_hash": "a41dbc712254e0c69cf819db7c4af52e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-5-building-your-first-agent-with-create_agent\">Task 5: Building Your First Agent with <code>create_agent()</code></h2>\n<span class=\"paragraph\">Let's build a simple agent that can perform calculations and tell the time.</span>\n<h3 id=\"step-1-define-tools\">Step 1: Define Tools</h3>\n<span class=\"paragraph\">Tools are functions that the agent can call. We use the <code>@tool</code> decorator to create them.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "iLit",
      "code_hash": "916314e4145df7662b0ba016ad92a935",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"step-2-create-the-agent\">Step 2: Create the Agent</h3>\n<span class=\"paragraph\">Now we use <code>create_agent</code> to build our agent. The function takes:</span>\n<ul>\n<li><code>model</code>: The LLM to use (can be a string like <code>\"gpt-5\"</code> or a model instance)</li>\n<li><code>tools</code>: List of tools the agent can use</li>\n<li><code>prompt</code>: Optional system prompt to customize behavior</li>\n</ul></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ROlb",
      "code_hash": "cf08cf577a88c3f90e3283b20a80ecb6",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"step-3-run-the-agent\">Step 3: Run the Agent</h3>\n<span class=\"paragraph\">The agent is a Runnable, so we can invoke it like any other LangChain component.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "DnEU",
      "code_hash": "25ef52ab1a7e0b91f9def2bda1f946f3",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"streaming-agent-responses\">Streaming Agent Responses</h3>\n<span class=\"paragraph\">For better UX, we can stream the agent's responses as they're generated.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ecfG",
      "code_hash": "19ef0986170f92ec75041a46c26776f5",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><hr />\n<h2 id=\"question-1\">\u2753 Question #1:</h2>\n<span class=\"paragraph\">In the agent loop, what determines whether the agent continues to call tools or returns a final answer to the user? How does <code>create_agent</code> handle this decision internally?</span>\n<h5 id=\"answer\">\u2705 Answer:</h5>\n<span class=\"paragraph\"><em>Your answer here</em></span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Pvdt",
      "code_hash": "1a4c6f5becae9e22476aafe5a0c37e85",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"question-2\">\u2753 Question #2:</h2>\n<span class=\"paragraph\">Looking at the <code>calculate</code> and <code>get_current_time</code> tools we created, why is the <strong>docstring</strong> so important for each tool? How does the agent use this information when deciding which tool to call?</span>\n<h5 id=\"answer\">\u2705 Answer:</h5>\n<span class=\"paragraph\"><em>Your answer here</em></span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ZBYS",
      "code_hash": "d1f1b87da9ba778668d30f64dfb65cd4",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><hr />\n<h2 id=\"activity-1-create-a-custom-tool\">\ud83c\udfd7\ufe0f Activity #1: Create a Custom Tool</h2>\n<span class=\"paragraph\">Create your own custom tool and add it to the agent!</span>\n<span class=\"paragraph\">Ideas:</span>\n<ul>\n<li>A tool that converts temperatures between Celsius and Fahrenheit</li>\n<li>A tool that generates a random number within a range</li>\n<li>A tool that counts words in a given text</li>\n</ul>\n<span class=\"paragraph\">Requirements:</span>\n<ol>\n<li>Use the <code>@tool</code> decorator</li>\n<li>Include a clear docstring (this is what the agent sees!)</li>\n<li>Add it to the agent and test it</li>\n</ol></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "xXTn",
      "code_hash": "d320d8ffbae1c8cb0965e3028fe2166c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><hr />\n<h1 id=\"breakout-room-2\">\ud83e\udd1d Breakout Room #2</h1>\n<h2 id=\"middleware-agentic-rag-with-qdrant\">Middleware - Agentic RAG with Qdrant</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "AjVT",
      "code_hash": "8e8174798a720a747ea083d460035fa7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Now that we understand the basics of agents, let's build something more powerful: an <strong>Agentic RAG</strong> system.</span>\n<span class=\"paragraph\">Traditional RAG follows a fixed pattern: retrieve \u2192 generate. But <strong>Agentic RAG</strong> gives the agent control over when and how to retrieve information, making it more flexible and intelligent.</span>\n<span class=\"paragraph\">We'll also introduce <strong>middleware</strong> - hooks that let us customize the agent's behavior at every step.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "pHFh",
      "code_hash": "4dcb69eace2245bd87a84b4e55271ce5",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-6-loading-chunking-documents\">Task 6: Loading &amp; Chunking Documents</h2>\n<span class=\"paragraph\">We'll use the same Health &amp; Wellness Guide from Session 2 to maintain continuity.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "TRpd",
      "code_hash": "ae41c37c0fc28370f5db4eee1b40b014",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-7-setting-up-qdrant-vector-database\">Task 7: Setting up Qdrant Vector Database</h2>\n<span class=\"paragraph\">Qdrant is a production-ready vector database. We'll use an in-memory instance for development, but the same code works with a hosted Qdrant instance.</span>\n<span class=\"paragraph\">Key concepts:</span>\n<ul>\n<li><strong>Collection</strong>: A namespace for storing vectors (like a table in SQL)</li>\n<li><strong>Points</strong>: Individual vectors with optional payloads (metadata)</li>\n<li><strong>Distance</strong>: How similarity is measured (we'll use cosine similarity)</li>\n</ul></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "kqZH",
      "code_hash": "5f931c16dd07f15a23394a042fdf4df7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-8-creating-a-rag-tool\">Task 8: Creating a RAG Tool</h2>\n<span class=\"paragraph\">Now we'll wrap our retriever as a tool that the agent can use. This is the key to <strong>Agentic RAG</strong> - the agent decides when to retrieve information.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "rEll",
      "code_hash": "d687f774fabafd1c7565c335883ab0a7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-9-introduction-to-middleware\">Task 9: Introduction to Middleware</h2>\n<span class=\"paragraph\"><strong>Middleware</strong> in LangChain 1.0 allows you to hook into the agent loop at various points:</span>\n<div class=\"language-brainfuck codehilite\"><pre><span></span><code><span class=\"c\">                       MIDDLEWARE HOOKS</span>\n\n<span class=\"c\">   </span><span class=\"nb\">+--------------+</span><span class=\"c\">                    </span><span class=\"nb\">+--------------+</span>\n<span class=\"c\">   | before_model | </span><span class=\"nb\">--</span><span class=\"nv\">&gt;</span><span class=\"c\"> MODEL CALL </span><span class=\"nb\">--</span><span class=\"nv\">&gt;</span><span class=\"c\"> | after_model  |</span>\n<span class=\"c\">   </span><span class=\"nb\">+--------------+</span><span class=\"c\">                    </span><span class=\"nb\">+--------------+</span>\n\n<span class=\"c\">   </span><span class=\"nb\">+-------------------+</span>\n<span class=\"c\">   | wrap_model_call   |  (intercept and modify calls)</span>\n<span class=\"c\">   </span><span class=\"nb\">+-------------------+</span>\n</code></pre></div>\n<span class=\"paragraph\">Common use cases:</span>\n<ul>\n<li><strong>Logging</strong>: Track what the agent is doing</li>\n<li><strong>Guardrails</strong>: Filter or modify inputs/outputs</li>\n<li><strong>Rate limiting</strong>: Control API usage</li>\n<li><strong>Human-in-the-loop</strong>: Pause for human approval</li>\n</ul>\n<span class=\"paragraph\">LangChain provides middleware through <strong>decorator functions</strong> that hook into specific points in the agent loop.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "lgWD",
      "code_hash": "5fe78c6c2a9f483c70ad301e7a197e45",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"task-10-building-agentic-rag-with-middleware\">Task 10: Building Agentic RAG with Middleware</h2>\n<span class=\"paragraph\">Now let's put it all together: an agentic RAG system with middleware support!</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "jxvo",
      "code_hash": "1be1cbacab035fa641ccb6d062dc18b8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"visualizing-the-agent\">Visualizing the Agent</h3>\n<span class=\"paragraph\">The agent created by <code>create_agent</code> is built on LangGraph, so we can visualize its structure.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "CcZR",
      "code_hash": "3d5fbe921f16ae26ea1518810f60ac04",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><hr />\n<h2 id=\"question-3\">\u2753 Question #3:</h2>\n<span class=\"paragraph\">How does <strong>Agentic RAG</strong> differ from traditional RAG? What are the advantages and potential disadvantages of letting the agent decide when to retrieve information?</span>\n<h5 id=\"answer\">\u2705 Answer:</h5>\n<span class=\"paragraph\"><em>Your answer here</em></span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "YWSi",
      "code_hash": "63245b3faf740046ead035e2475ef867",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"question-4\">\u2753 Question #4:</h2>\n<span class=\"paragraph\">Looking at the middleware examples (<code>log_before_model</code>, <code>log_after_model</code>, and <code>ModelCallLimitMiddleware</code>), describe a real-world scenario where middleware would be essential for a production agent. What specific middleware hooks would you use and why?</span>\n<h5 id=\"answer\">\u2705 Answer:</h5>\n<span class=\"paragraph\"><em>Your answer here</em></span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "zlud",
      "code_hash": "0d2258e9d131ac42e1fc476f20397021",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><hr />\n<h2 id=\"activity-2-enhance-the-agentic-rag-system\">\ud83c\udfd7\ufe0f Activity #2: Enhance the Agentic RAG System</h2>\n<span class=\"paragraph\">Now it's your turn! Enhance the wellness agent by implementing ONE of the following:</span>\n<h3 id=\"option-a-add-a-new-tool\">Option A: Add a New Tool</h3>\n<span class=\"paragraph\">Create a new tool that the agent can use. Ideas:</span>\n<ul>\n<li>A tool that calculates BMI given height and weight</li>\n<li>A tool that estimates daily calorie needs</li>\n<li>A tool that creates a simple workout plan</li>\n</ul>\n<h3 id=\"option-b-create-custom-middleware\">Option B: Create Custom Middleware</h3>\n<span class=\"paragraph\">Build middleware that adds new functionality:</span>\n<ul>\n<li>Middleware that tracks which tools are used most frequently</li>\n<li>Middleware that adds a friendly greeting to responses</li>\n<li>Middleware that enforces a response length limit</li>\n</ul>\n<h3 id=\"option-c-improve-the-rag-tool\">Option C: Improve the RAG Tool</h3>\n<span class=\"paragraph\">Enhance the retrieval tool:</span>\n<ul>\n<li>Add metadata filtering</li>\n<li>Implement reranking of results</li>\n<li>Add source citations with relevance scores</li>\n</ul></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "bkHC",
      "code_hash": "c1de39be12b58aed65d724213b1babdd",
      "outputs": [],
      "console": []
    },
    {
      "id": "lEQa",
      "code_hash": "f5d5cb0314399dab2c2428435f58d9e7",
      "outputs": [],
      "console": []
    },
    {
      "id": "Xref",
      "code_hash": "1da13b17a6053d7781428960bd2445fd",
      "outputs": [],
      "console": []
    },
    {
      "id": "SFPL",
      "code_hash": "438c2e1086a9f59852f2478fad5d55aa",
      "outputs": [],
      "console": []
    },
    {
      "id": "RGSE",
      "code_hash": "b423603a6a14275e04bc20cfa4ba281c",
      "outputs": [],
      "console": []
    },
    {
      "id": "Kclp",
      "code_hash": "afe138c7e985c594cf43a6e41fa1d577",
      "outputs": [],
      "console": []
    },
    {
      "id": "nWHF",
      "code_hash": "50892249b7d2d766822308dda9ddf54c",
      "outputs": [],
      "console": []
    },
    {
      "id": "ZHCJ",
      "code_hash": "eb211269b8bcae35cced003d9c804d49",
      "outputs": [],
      "console": []
    },
    {
      "id": "qnkX",
      "code_hash": "671187e999c2c10c165b0dd746d2d9b4",
      "outputs": [],
      "console": []
    },
    {
      "id": "TqIu",
      "code_hash": "00e9047e82c98e4987f46eaf3c9f33af",
      "outputs": [],
      "console": []
    },
    {
      "id": "Vxnm",
      "code_hash": "5e1d212273ed65234c6cfaf1c0d9c24b",
      "outputs": [],
      "console": []
    },
    {
      "id": "ulZA",
      "code_hash": "6d075c734ba9975b384bdf663af0229c",
      "outputs": [],
      "console": []
    },
    {
      "id": "aLJB",
      "code_hash": "a469375f26fc4043a6f7a8a53867c7b6",
      "outputs": [],
      "console": []
    },
    {
      "id": "nHfw",
      "code_hash": "331876e743f6b11d86d785a7294965ca",
      "outputs": [],
      "console": []
    },
    {
      "id": "NCOB",
      "code_hash": "1fd578e8db5b26dab51ae74c57663091",
      "outputs": [],
      "console": []
    },
    {
      "id": "aqbW",
      "code_hash": "0556375ba2c69de91eaa46c316c19fa1",
      "outputs": [],
      "console": []
    },
    {
      "id": "TXez",
      "code_hash": "c72d00d60c8e942dd697d2003031d89c",
      "outputs": [],
      "console": []
    },
    {
      "id": "dNNg",
      "code_hash": "876de9cf228043553a1b6bb54067fe35",
      "outputs": [],
      "console": []
    },
    {
      "id": "yCnT",
      "code_hash": "b68f1ae9f7041aeef34776149f6a830f",
      "outputs": [],
      "console": []
    },
    {
      "id": "wlCL",
      "code_hash": "efbad3abbc945ca9869ae38e72236b4d",
      "outputs": [],
      "console": []
    },
    {
      "id": "wAgl",
      "code_hash": "7c99b57bab5dd3dc937196c2de0a8801",
      "outputs": [],
      "console": []
    },
    {
      "id": "dGlV",
      "code_hash": "46caa4e63a58153b82cd84ba55b3891b",
      "outputs": [],
      "console": []
    },
    {
      "id": "SdmI",
      "code_hash": "9bde224989f6e4e01994874ea8954cfd",
      "outputs": [],
      "console": []
    },
    {
      "id": "yOPj",
      "code_hash": "5e07b3ebb454ca52340ba44c21fea68f",
      "outputs": [],
      "console": []
    },
    {
      "id": "fwwy",
      "code_hash": "8558b3711d585795aee3728e6dd6a43a",
      "outputs": [],
      "console": []
    },
    {
      "id": "LJZf",
      "code_hash": "f23eeb1d6fb51ac7d19cbf76c2d8a0ba",
      "outputs": [],
      "console": []
    },
    {
      "id": "urSm",
      "code_hash": "3be6403cfb86583cb5b8432fad0862b6",
      "outputs": [],
      "console": []
    },
    {
      "id": "mWxS",
      "code_hash": "ec088727695bc3af93f91056d2f13e38",
      "outputs": [],
      "console": []
    },
    {
      "id": "tZnO",
      "code_hash": "a21a68673dcb4a0481433267b9f31964",
      "outputs": [],
      "console": []
    },
    {
      "id": "xvXZ",
      "code_hash": "c35c48be5c91a0506a6c225914c4e608",
      "outputs": [],
      "console": []
    },
    {
      "id": "CLip",
      "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e",
      "outputs": [],
      "console": []
    }
  ]
}